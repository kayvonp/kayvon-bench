active:
  llm_profile: together_gpt-oss-120b_private
  benchmark_profile: summarization_13000to600
providers:
  openai:
    base_url: https://api.openai.com/v1
    api_key_env: OPENAI_API_KEY
    api_style: responses
  together:
    base_url: https://api.together.xyz/v1
    api_key_env: TOGETHER_API_KEY
    api_style: chat_completions
llm_profiles:
  openai_fast:
    provider: openai
    model: gpt-5-nano
  together_gpt-oss-20b_public:
    provider: together
    model: openai/gpt-oss-20b
    reasoning_effort: high
  together_gpt-oss-20b_private:
    provider: together
    model: kpirestani_0236/openai/gpt-oss-20b-398585b7
    reasoning_effort: high
  together_gpt-oss-120b_private:
    provider: together
    model: kpirestani_0236/openai/gpt-oss-120b-2fefaac0
    reasoning_effort: high
  custom_example:
    provider: custom
    base_url: https://your-endpoint.example/v1
    api_key_env: YOUR_API_KEY_ENV
    api_style: chat_completions
    model: your/model-id
benchmark_profiles:
  summarization_13000to600:
    diagnostic_mode: true
    disable_max_completion_tokens: true
    dataset_path: corpus/v1_summarization_13000to600.jsonl
    sample_with_replacement: true
    random_seed: 42
    concurrency_levels:
    - 1
    - 2
    request_sizing:
      mode: concurrency_scaled
      waves_per_level: 8
      min_requests: 16
      max_requests: 256
    progress_update_every: 3
    request_timeout_s: 90
    stop_on_saturation: true
    min_levels_before_stop: 3
    saturation:
      throughput_plateau_pct: 0.03
      throughput_decline_pct: 0.07
      latency_spike_multiplier: 1.35
    token_diagnostics: true
